{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Embedding, LSTM,GRU, Dense, Dropout\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Clean_Hotel_Reviews_tfidf_remove_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Review</th>\n",
       "      <th>Days_stayed</th>\n",
       "      <th>Hotel_location</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Review_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13121</td>\n",
       "      <td>1 rue Geoffroy Marie 9th arr 75009 Paris France</td>\n",
       "      <td>40</td>\n",
       "      <td>12/3/2016</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Hotel Panache</td>\n",
       "      <td>Japan</td>\n",
       "      <td>one staff who can t speak English it was alwa...</td>\n",
       "      <td>37</td>\n",
       "      <td>371</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Classi...</td>\n",
       "      <td>243 day</td>\n",
       "      <td>48.873254</td>\n",
       "      <td>2.343239</td>\n",
       "      <td>one staff who can t speak English it was alwa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Paris France</td>\n",
       "      <td>one staff speak english alway tough commun som...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381307</td>\n",
       "      <td>Molenwerf 1 1014 AG Amsterdam Netherlands</td>\n",
       "      <td>914</td>\n",
       "      <td>10/4/2015</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Golden Tulip Amsterdam West</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>7586</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Standard Doub...</td>\n",
       "      <td>669 day</td>\n",
       "      <td>52.385601</td>\n",
       "      <td>4.847060</td>\n",
       "      <td>The coffee machine in the room</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Amsterdam Netherlands</td>\n",
       "      <td>coffe machin room</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264042</td>\n",
       "      <td>97 Great Russell Street Bloomsbury Camden Lond...</td>\n",
       "      <td>406</td>\n",
       "      <td>3/6/2017</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Radisson Blu Edwardian Kenilworth</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>rooms were lovely but very small Possibly a C...</td>\n",
       "      <td>18</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>[' Leisure trip ', ' Group ', ' Standard Doubl...</td>\n",
       "      <td>150 day</td>\n",
       "      <td>51.517972</td>\n",
       "      <td>-0.128049</td>\n",
       "      <td>rooms were lovely but very small Possibly a C...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>room love small possibl central london standar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294029</td>\n",
       "      <td>Capellans 4 Ciutat Vella 08002 Barcelona Spain</td>\n",
       "      <td>387</td>\n",
       "      <td>2/9/2017</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Hotel Barcelona Catedral</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Would be nice if the pool was heated</td>\n",
       "      <td>9</td>\n",
       "      <td>2695</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[' Business trip ', ' Solo traveler ', ' Doubl...</td>\n",
       "      <td>175 day</td>\n",
       "      <td>41.384829</td>\n",
       "      <td>2.175128</td>\n",
       "      <td>Would be nice if the pool was heated Location...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona Spain</td>\n",
       "      <td>would nice pool heat locat great staff super h...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11690</td>\n",
       "      <td>1 Kings Cross Road Islington London WC1X 9HX U...</td>\n",
       "      <td>628</td>\n",
       "      <td>3/23/2016</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Crowne Plaza London Kings Cross</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2312</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Standard Room...</td>\n",
       "      <td>498 day</td>\n",
       "      <td>51.526385</td>\n",
       "      <td>-0.113604</td>\n",
       "      <td>I had a refurbished room and it was perfect I...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>refurbish room perfect got room servic everyon...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      Hotel_Address  \\\n",
       "0       13121    1 rue Geoffroy Marie 9th arr 75009 Paris France   \n",
       "1      381307          Molenwerf 1 1014 AG Amsterdam Netherlands   \n",
       "2      264042  97 Great Russell Street Bloomsbury Camden Lond...   \n",
       "3      294029     Capellans 4 Ciutat Vella 08002 Barcelona Spain   \n",
       "4       11690  1 Kings Cross Road Islington London WC1X 9HX U...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score  \\\n",
       "0                            40   12/3/2016            8.6   \n",
       "1                           914   10/4/2015            8.5   \n",
       "2                           406    3/6/2017            8.2   \n",
       "3                           387    2/9/2017            8.9   \n",
       "4                           628   3/23/2016            8.1   \n",
       "\n",
       "                          Hotel_Name Reviewer_Nationality  \\\n",
       "0                      Hotel Panache               Japan    \n",
       "1        Golden Tulip Amsterdam West      United Kingdom    \n",
       "2  Radisson Blu Edwardian Kenilworth      United Kingdom    \n",
       "3           Hotel Barcelona Catedral      United Kingdom    \n",
       "4    Crowne Plaza London Kings Cross      United Kingdom    \n",
       "\n",
       "                                     Negative_Review  \\\n",
       "0   one staff who can t speak English it was alwa...   \n",
       "1                                        No Negative   \n",
       "2   rooms were lovely but very small Possibly a C...   \n",
       "3               Would be nice if the pool was heated   \n",
       "4                                        No Negative   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  ...  \\\n",
       "0                                 37                      371  ...   \n",
       "1                                  0                     7586  ...   \n",
       "2                                 18                     2011  ...   \n",
       "3                                  9                     2695  ...   \n",
       "4                                  0                     2312  ...   \n",
       "\n",
       "  Reviewer_Score                                               Tags  \\\n",
       "0           10.0  [' Leisure trip ', ' Solo traveler ', ' Classi...   \n",
       "1            7.9  [' Leisure trip ', ' Couple ', ' Standard Doub...   \n",
       "2            9.6  [' Leisure trip ', ' Group ', ' Standard Doubl...   \n",
       "3            8.3  [' Business trip ', ' Solo traveler ', ' Doubl...   \n",
       "4           10.0  [' Leisure trip ', ' Couple ', ' Standard Room...   \n",
       "\n",
       "   days_since_review        lat       lng  \\\n",
       "0            243 day  48.873254  2.343239   \n",
       "1            669 day  52.385601  4.847060   \n",
       "2            150 day  51.517972 -0.128049   \n",
       "3            175 day  41.384829  2.175128   \n",
       "4            498 day  51.526385 -0.113604   \n",
       "\n",
       "                                              Review  Days_stayed  \\\n",
       "0   one staff who can t speak English it was alwa...          2.0   \n",
       "1                     The coffee machine in the room          2.0   \n",
       "2   rooms were lovely but very small Possibly a C...          2.0   \n",
       "3   Would be nice if the pool was heated Location...          1.0   \n",
       "4   I had a refurbished room and it was perfect I...          1.0   \n",
       "\n",
       "          Hotel_location                                     Cleaned_Review  \\\n",
       "0           Paris France  one staff speak english alway tough commun som...   \n",
       "1  Amsterdam Netherlands                                  coffe machin room   \n",
       "2         United Kingdom  room love small possibl central london standar...   \n",
       "3        Barcelona Spain  would nice pool heat locat great staff super h...   \n",
       "4         United Kingdom  refurbish room perfect got room servic everyon...   \n",
       "\n",
       "   Review_Class  \n",
       "0           pos  \n",
       "1           pos  \n",
       "2           pos  \n",
       "3           pos  \n",
       "4           pos  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Naive Bayes by BOW and TFIDF vector as the baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetorize by bag of words and tfidf \n",
    "vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_bow=vectorizer.fit_transform(df['Cleaned_Review'].values)\n",
    "X_tfidf=tfidf_vectorizer.fit_transform(df['Cleaned_Review'].values) \n",
    "\n",
    "X_train_bow, X_test, y_train_bow, y_test = train_test_split(X_bow, df['Review_Class'], test_size=0.2,shuffle=True,random_state=1)\n",
    "X_train_tfidf, X_test, y_train_tfidf, y_test = train_test_split(X_tfidf, df['Review_Class'], test_size=0.2,shuffle=True,random_state=1)\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,shuffle=True,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def NB_train_test(X_train,X_val,y_train,y_val):\n",
    "    mnb = MultinomialNB() \n",
    "    mnb.fit(X_train, y_train)\n",
    "    result=pd.DataFrame({'Model':'NB','train_accu':[mnb.score(X_train,y_train)],'test_accu':[mnb.score(X_val,y_val)]})\n",
    "    return result\n",
    "\n",
    "def NB_get_all_fold_result(data_X,data_y):\n",
    "    all_folds_result=pd.DataFrame([])\n",
    "    for train_index, val_index in kf.split(data_X):\n",
    "        X_train_fold, X_test_fold = data_X[train_index], data_X[val_index]\n",
    "        y_train_fold, y_test_fold = data_y[train_index], data_y[val_index]\n",
    "        nfold_result=NB_train_test(X_train_fold, X_test_fold, y_train_fold, y_test_fold)\n",
    "        all_folds_result=all_folds_result.append(nfold_result)\n",
    "        \n",
    "    mean_result=pd.DataFrame(all_folds_result.mean()).T\n",
    "    mean_result.rename({'train_accu':'mean_train_accu','test_accu':'mean_test_accu'},axis=1,inplace=True)\n",
    "    mean_result['model']=\"NB\"\n",
    "    return mean_result\n",
    "\n",
    "NB_bow_meanfold_result=NB_get_all_fold_result(X_train_bow,df['Review_Class'])\n",
    "NB_tfidf_meanfold_result=NB_get_all_fold_result(X_train_tfidf,df['Review_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accu</th>\n",
       "      <th>mean_test_accu</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562303</td>\n",
       "      <td>0.413938</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accu  mean_test_accu model\n",
       "0         0.562303        0.413938    NB"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_tfidf_meanfold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accu</th>\n",
       "      <th>mean_test_accu</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568457</td>\n",
       "      <td>0.410566</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accu  mean_test_accu model\n",
       "0         0.568457        0.410566    NB"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_bow_meanfold_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load reviews' sequencial tokenid and word2id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ordered_review_tokenid_sampled.pkl'\n",
    "inputfile = open(filename,'rb')\n",
    "cleaned_rev_nums=pickle.load(inputfile)\n",
    "inputfile.close()\n",
    "\n",
    "word2idfile = open('word2id_sampled.pkl','rb')\n",
    "word2id=pickle.load(word2idfile)\n",
    "word2idfile.close()\n",
    "\n",
    "vocabulary_size=len(word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical columns encoding and train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53380, 368)\n",
      "(53380, 3)\n"
     ]
    }
   ],
   "source": [
    "def transform_to_onehot(data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(data)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n",
    "\n",
    "def generate_added_features(df):\n",
    "    nation_label_encoder = LabelEncoder()\n",
    "    nationality_encoded = nation_label_encoder.fit_transform(df['Reviewer_Nationality'])\n",
    "    location_label_encoder = LabelEncoder()\n",
    "    location_encoded = location_label_encoder.fit_transform(df['Hotel_location'])\n",
    "    added_features=np.concatenate((nationality_encoded.reshape(-1,1),location_encoded.reshape(-1,1),df['Days_stayed'].values.reshape(-1,1)),axis=1)\n",
    "    return added_features\n",
    "\n",
    "#sequence padding to the maximum length\n",
    "X_seq=np.array(cleaned_rev_nums)\n",
    "X_seq_padded=sequence.pad_sequences(X_seq, maxlen=max_len)\n",
    "y_seq_onehot=transform_to_onehot(data=df['Review_Class'].values)\n",
    "#preprocess added features(hotel location, revitaewer nationality and days stayes)\n",
    "added_features=generate_added_features(df)\n",
    "\n",
    "#train test split \n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq_padded,y_seq_onehot, test_size=0.2,shuffle=True,random_state=1)\n",
    "X_train_added, X_test_added, _, _ = train_test_split(added_features,added_features, test_size=0.2,shuffle=False )\n",
    "print(X_train_seq.shape)\n",
    "print(X_train_added.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU model building and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added=True\n",
    "embedding_size=64\n",
    "added_shape=added_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "167/167 [==============================] - 74s 441ms/step - loss: 0.8509 - accuracy: 0.5919\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 101s 603ms/step - loss: 0.6776 - accuracy: 0.6928\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 100s 599ms/step - loss: 0.6228 - accuracy: 0.7256\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 93s 554ms/step - loss: 0.5837 - accuracy: 0.7475\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 89s 533ms/step - loss: 0.5487 - accuracy: 0.7652\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 81s 484ms/step - loss: 0.5196 - accuracy: 0.7809\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 80s 477ms/step - loss: 0.4912 - accuracy: 0.7939\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 80s 479ms/step - loss: 0.4670 - accuracy: 0.8049\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 81s 482ms/step - loss: 0.4437 - accuracy: 0.8161\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 81s 485ms/step - loss: 0.4207 - accuracy: 0.8272\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 80s 479ms/step - loss: 0.3992 - accuracy: 0.8369\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 0.3844 - accuracy: 0.8423\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 84s 501ms/step - loss: 0.3686 - accuracy: 0.8505\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 87s 519ms/step - loss: 0.3549 - accuracy: 0.8552\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 83s 494ms/step - loss: 0.3445 - accuracy: 0.8604\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 82s 494ms/step - loss: 0.3346 - accuracy: 0.8640\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 82s 492ms/step - loss: 0.3222 - accuracy: 0.8701\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 80s 481ms/step - loss: 0.3195 - accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 79s 470ms/step - loss: 0.3041 - accuracy: 0.8786\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 79s 474ms/step - loss: 0.2961 - accuracy: 0.8815\n",
      "334/334 [==============================] - 8s 24ms/step - loss: 1.3699 - accuracy: 0.6250\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 79s 476ms/step - loss: 0.8488 - accuracy: 0.5914\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 81s 486ms/step - loss: 0.6741 - accuracy: 0.6943\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 88s 526ms/step - loss: 0.6239 - accuracy: 0.7230\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 87s 520ms/step - loss: 0.5857 - accuracy: 0.7469\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 85s 510ms/step - loss: 0.5536 - accuracy: 0.7632\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 87s 523ms/step - loss: 0.5249 - accuracy: 0.7753\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 85s 508ms/step - loss: 0.4985 - accuracy: 0.7890\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 89s 532ms/step - loss: 0.4722 - accuracy: 0.8009\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 90s 541ms/step - loss: 0.4475 - accuracy: 0.8141\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 82s 490ms/step - loss: 0.4244 - accuracy: 0.8238\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 79s 476ms/step - loss: 0.4159 - accuracy: 0.8281\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 79s 475ms/step - loss: 0.3900 - accuracy: 0.8394\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 87s 519ms/step - loss: 0.3708 - accuracy: 0.8476\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 93s 556ms/step - loss: 0.3536 - accuracy: 0.8561\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 88s 527ms/step - loss: 0.3418 - accuracy: 0.8611\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 89s 534ms/step - loss: 0.3319 - accuracy: 0.8652\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 90s 539ms/step - loss: 0.3224 - accuracy: 0.8703\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 87s 521ms/step - loss: 0.3067 - accuracy: 0.8761\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 82s 493ms/step - loss: 0.3071 - accuracy: 0.8752\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 86s 515ms/step - loss: 0.2965 - accuracy: 0.8808\n",
      "334/334 [==============================] - 8s 24ms/step - loss: 1.2950 - accuracy: 0.6279\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 93s 556ms/step - loss: 0.8377 - accuracy: 0.5988\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 102s 611ms/step - loss: 0.6735 - accuracy: 0.6962\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 103s 615ms/step - loss: 0.6208 - accuracy: 0.7256\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 92s 552ms/step - loss: 0.5818 - accuracy: 0.7480\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 92s 553ms/step - loss: 0.5470 - accuracy: 0.7662\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 93s 557ms/step - loss: 0.5169 - accuracy: 0.7803\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 95s 568ms/step - loss: 0.4883 - accuracy: 0.7944\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 94s 562ms/step - loss: 0.4631 - accuracy: 0.8074\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 93s 557ms/step - loss: 0.4380 - accuracy: 0.8179\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 93s 556ms/step - loss: 0.4165 - accuracy: 0.8297\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 92s 548ms/step - loss: 0.3972 - accuracy: 0.8399\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 85s 507ms/step - loss: 0.3802 - accuracy: 0.8455\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 85s 512ms/step - loss: 0.3638 - accuracy: 0.8526\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 89s 533ms/step - loss: 0.3533 - accuracy: 0.8569\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 88s 527ms/step - loss: 0.3371 - accuracy: 0.8645\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 88s 529ms/step - loss: 0.3261 - accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 89s 533ms/step - loss: 0.3149 - accuracy: 0.8737\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 2504s 15s/step - loss: 0.3061 - accuracy: 0.8780\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 71s 426ms/step - loss: 0.2942 - accuracy: 0.8828\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 4340s 26s/step - loss: 0.2865 - accuracy: 0.8867\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 1.3903 - accuracy: 0.6147\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 19552s 117s/step - loss: 0.8485 - accuracy: 0.5902\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 72s 430ms/step - loss: 0.6781 - accuracy: 0.6941\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 73s 437ms/step - loss: 0.6282 - accuracy: 0.7235\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 76s 452ms/step - loss: 0.5903 - accuracy: 0.7426\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 76s 455ms/step - loss: 0.5595 - accuracy: 0.7600\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 76s 453ms/step - loss: 0.5298 - accuracy: 0.7763\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 75s 448ms/step - loss: 0.5025 - accuracy: 0.7875\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 74s 445ms/step - loss: 0.4770 - accuracy: 0.8009\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 75s 446ms/step - loss: 0.4561 - accuracy: 0.8111\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 75s 448ms/step - loss: 0.4304 - accuracy: 0.8219\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 75s 447ms/step - loss: 0.4115 - accuracy: 0.8310\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 9506s 57s/step - loss: 0.3912 - accuracy: 0.8401\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 30178s 181s/step - loss: 0.3760 - accuracy: 0.8458\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 85s 512ms/step - loss: 0.3605 - accuracy: 0.8531\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 77s 463ms/step - loss: 0.3468 - accuracy: 0.8593\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 78s 465ms/step - loss: 0.3386 - accuracy: 0.8619\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 78s 467ms/step - loss: 0.3270 - accuracy: 0.8679\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 79s 475ms/step - loss: 0.3255 - accuracy: 0.8690\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 0.3067 - accuracy: 0.8774\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 78s 467ms/step - loss: 0.2934 - accuracy: 0.8829\n",
      "334/334 [==============================] - 8s 23ms/step - loss: 1.3408 - accuracy: 0.6230\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 77s 461ms/step - loss: 0.8452 - accuracy: 0.5932\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 77s 463ms/step - loss: 0.6727 - accuracy: 0.6965\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 0.6215 - accuracy: 0.7272\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 78s 469ms/step - loss: 0.5830 - accuracy: 0.7478\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 78s 468ms/step - loss: 0.5499 - accuracy: 0.7646\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 77s 463ms/step - loss: 0.5206 - accuracy: 0.7806\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 82s 493ms/step - loss: 0.4925 - accuracy: 0.7927\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 85s 507ms/step - loss: 0.4672 - accuracy: 0.8046\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 86s 514ms/step - loss: 0.4428 - accuracy: 0.8177\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 87s 518ms/step - loss: 0.4212 - accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 88s 525ms/step - loss: 0.4017 - accuracy: 0.8337\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 83s 496ms/step - loss: 0.3824 - accuracy: 0.8434\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 83s 498ms/step - loss: 0.3688 - accuracy: 0.8491\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 89s 535ms/step - loss: 0.3540 - accuracy: 0.8557\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 88s 527ms/step - loss: 0.3418 - accuracy: 0.8613\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 82s 491ms/step - loss: 0.3301 - accuracy: 0.8652\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 84s 505ms/step - loss: 0.3220 - accuracy: 0.8707\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 89s 530ms/step - loss: 0.3096 - accuracy: 0.8735\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 92s 548ms/step - loss: 0.3070 - accuracy: 0.8757\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 92s 553ms/step - loss: 0.2959 - accuracy: 0.8800\n",
      "334/334 [==============================] - 8s 25ms/step - loss: 1.3998 - accuracy: 0.6172\n"
     ]
    }
   ],
   "source": [
    "#GRU \n",
    "def my_GRU_model(vocabulary_size,embedding_size,input_length):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_size, input_length=input_length))\n",
    "    model.add(GRU(50))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def GRU_train_test(X_train,X_val,y_train,y_val,vocabulary_size, embedding_size,input_length):\n",
    "    #model = my_GRU_model_concat(vocabulary_size, embedding_size,input_length) \n",
    "    model = my_GRU_model(vocabulary_size, embedding_size,input_length)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer='adam', \n",
    "                 metrics=['accuracy'])\n",
    "    history_gru=model.fit(X_train,y_train,batch_size=256,epochs=20)  #,validation_data=(x_val, y_val)\n",
    "    test_result_gru=model.evaluate(X_val,y_val)\n",
    "    train_loss_gru,train_accu_gru=history_gru.history['loss'],history_gru.history['accuracy']\n",
    "    result=pd.DataFrame({'Model':'GRU','train_accu':[np.mean(train_accu_gru)],'test_accu':[test_result_gru[-1]]})\n",
    "    return result\n",
    "\n",
    "\n",
    "def GRU_get_all_fold_result(data_X,data_y,vocabulary_size, embedding_size,input_length):\n",
    "    all_folds_result=pd.DataFrame([])\n",
    "    for train_index, val_index in kf.split(data_X):\n",
    "        X_train_fold, X_test_fold = data_X[train_index], data_X[val_index]\n",
    "        y_train_fold, y_test_fold = data_y[train_index], data_y[val_index]      \n",
    "        nfold_result = GRU_train_test(X_train_fold,X_test_fold, y_train_fold, y_test_fold,vocabulary_size, embedding_size,input_length)\n",
    "        all_folds_result=all_folds_result.append(nfold_result)\n",
    "    mean_result=pd.DataFrame(all_folds_result.mean()).T\n",
    "    mean_result.rename({'train_accu':'mean_train_accu','test_accu':'mean_test_accu'},axis=1,inplace=True)\n",
    "    mean_result['model']=\"GRU\"\n",
    "    return mean_result\n",
    "\n",
    "GRU_meanfold_result=GRU_get_all_fold_result(X_train_seq,y_train_seq,vocabulary_size, embedding_size,input_length=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 9.0789 - accuracy: 0.3339\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 80s 481ms/step - loss: 2.3720 - accuracy: 0.3536\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 81s 485ms/step - loss: 1.0307 - accuracy: 0.5600\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 89s 532ms/step - loss: 0.7029 - accuracy: 0.6856\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 82s 490ms/step - loss: 0.6453 - accuracy: 0.7163\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 80s 478ms/step - loss: 0.6079 - accuracy: 0.7356\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 87s 522ms/step - loss: 0.5753 - accuracy: 0.7527\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 88s 526ms/step - loss: 0.5445 - accuracy: 0.7703\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 88s 524ms/step - loss: 0.5173 - accuracy: 0.7844\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 87s 522ms/step - loss: 0.4888 - accuracy: 0.7969\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 86s 513ms/step - loss: 0.4648 - accuracy: 0.8095\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 85s 506ms/step - loss: 0.4411 - accuracy: 0.8206\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 84s 502ms/step - loss: 0.4219 - accuracy: 0.8295\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 83s 495ms/step - loss: 0.4027 - accuracy: 0.8382\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 84s 505ms/step - loss: 0.3829 - accuracy: 0.8469\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 81s 483ms/step - loss: 0.3678 - accuracy: 0.8522\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 79s 475ms/step - loss: 0.3529 - accuracy: 0.8601\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 81s 483ms/step - loss: 0.3397 - accuracy: 0.8650\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 82s 488ms/step - loss: 0.3255 - accuracy: 0.8710\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 82s 489ms/step - loss: 0.3163 - accuracy: 0.8746\n",
      "334/334 [==============================] - 8s 25ms/step - loss: 1.1780 - accuracy: 0.6299\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 87s 523ms/step - loss: 1.3446 - accuracy: 0.4718\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 96s 575ms/step - loss: 0.7240 - accuracy: 0.6697\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 100s 601ms/step - loss: 0.6519 - accuracy: 0.7078\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 92s 552ms/step - loss: 0.6108 - accuracy: 0.7333\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 87s 521ms/step - loss: 0.5765 - accuracy: 0.7507\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 84s 502ms/step - loss: 0.5465 - accuracy: 0.7677\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 84s 504ms/step - loss: 0.5193 - accuracy: 0.7783\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 85s 509ms/step - loss: 0.4910 - accuracy: 0.7934\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 85s 506ms/step - loss: 0.4647 - accuracy: 0.8049\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 86s 514ms/step - loss: 0.4382 - accuracy: 0.8199\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 80s 481ms/step - loss: 0.4138 - accuracy: 0.8295\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 80s 482ms/step - loss: 0.3910 - accuracy: 0.8396\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 311s 2s/step - loss: 0.3722 - accuracy: 0.8468\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 73s 435ms/step - loss: 0.3593 - accuracy: 0.8524\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 334s 2s/step - loss: 0.3429 - accuracy: 0.8612\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 70s 421ms/step - loss: 0.3302 - accuracy: 0.8669\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 80s 481ms/step - loss: 0.3184 - accuracy: 0.8707\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 451s 3s/step - loss: 0.3065 - accuracy: 0.8771\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 113s 679ms/step - loss: 0.2989 - accuracy: 0.8795\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 227s 1s/step - loss: 0.2879 - accuracy: 0.8851\n",
      "334/334 [==============================] - 23s 68ms/step - loss: 1.4137 - accuracy: 0.6339\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 223s 1s/step - loss: 4.0454 - accuracy: 0.3595\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 224s 1s/step - loss: 0.8886 - accuracy: 0.5821\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 286s 2s/step - loss: 0.7074 - accuracy: 0.6796\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 0.6509 - accuracy: 0.7121\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 81s 483ms/step - loss: 0.6106 - accuracy: 0.7329\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 82s 489ms/step - loss: 0.5772 - accuracy: 0.7508\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 82s 488ms/step - loss: 0.5490 - accuracy: 0.7664\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 80s 480ms/step - loss: 0.5266 - accuracy: 0.7777\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 79s 472ms/step - loss: 0.5013 - accuracy: 0.7908\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 580s 3s/step - loss: 0.4814 - accuracy: 0.8012\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 79s 476ms/step - loss: 0.4586 - accuracy: 0.8106\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 82s 493ms/step - loss: 0.4394 - accuracy: 0.8206\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 85s 507ms/step - loss: 0.4200 - accuracy: 0.8284\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 87s 519ms/step - loss: 0.4033 - accuracy: 0.8363\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 86s 514ms/step - loss: 0.3853 - accuracy: 0.8440\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 83s 496ms/step - loss: 0.3687 - accuracy: 0.8512\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 81s 486ms/step - loss: 0.3529 - accuracy: 0.8593\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 79s 471ms/step - loss: 0.3395 - accuracy: 0.8656\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 79s 472ms/step - loss: 0.3265 - accuracy: 0.8691\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 93s 555ms/step - loss: 0.3156 - accuracy: 0.8745\n",
      "334/334 [==============================] - 9s 27ms/step - loss: 1.2363 - accuracy: 0.6200\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 91s 546ms/step - loss: 6.4298 - accuracy: 0.3376\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 92s 550ms/step - loss: 1.5762 - accuracy: 0.3971\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 89s 536ms/step - loss: 0.8030 - accuracy: 0.6233\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 89s 536ms/step - loss: 0.6828 - accuracy: 0.6936\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 86s 517ms/step - loss: 0.6360 - accuracy: 0.7208\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 89s 533ms/step - loss: 0.5972 - accuracy: 0.7400\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 91s 543ms/step - loss: 0.5664 - accuracy: 0.7575\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 86s 516ms/step - loss: 0.5407 - accuracy: 0.7721\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 80s 479ms/step - loss: 0.5139 - accuracy: 0.7862\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 80s 477ms/step - loss: 0.4899 - accuracy: 0.7986\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 80s 478ms/step - loss: 0.4664 - accuracy: 0.8103\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 82s 492ms/step - loss: 0.4463 - accuracy: 0.8206\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 80s 479ms/step - loss: 0.4267 - accuracy: 0.8280\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 80s 477ms/step - loss: 0.4074 - accuracy: 0.8364\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 80s 479ms/step - loss: 0.3901 - accuracy: 0.8436\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 251s 2s/step - loss: 0.3740 - accuracy: 0.8524\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 1264s 8s/step - loss: 0.3575 - accuracy: 0.8587\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 171s 1s/step - loss: 0.3432 - accuracy: 0.8630\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 74s 446ms/step - loss: 0.3331 - accuracy: 0.8680\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 82s 493ms/step - loss: 0.3188 - accuracy: 0.8746\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 1.2402 - accuracy: 0.6233\n",
      "Epoch 1/20\n",
      "167/167 [==============================] - 84s 503ms/step - loss: 9.4829 - accuracy: 0.3355\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 82s 490ms/step - loss: 2.2472 - accuracy: 0.4123\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 81s 483ms/step - loss: 0.8011 - accuracy: 0.6330\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 82s 491ms/step - loss: 0.6775 - accuracy: 0.6930\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 93s 558ms/step - loss: 0.6288 - accuracy: 0.7221\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 104s 620ms/step - loss: 0.5919 - accuracy: 0.7410\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 90s 541ms/step - loss: 0.5589 - accuracy: 0.7593\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 89s 535ms/step - loss: 0.5291 - accuracy: 0.7750\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 87s 520ms/step - loss: 0.5022 - accuracy: 0.7887\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 96s 575ms/step - loss: 0.4758 - accuracy: 0.8012\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 88s 527ms/step - loss: 0.4535 - accuracy: 0.8142\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 92s 549ms/step - loss: 0.4309 - accuracy: 0.8251\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 95s 569ms/step - loss: 0.4103 - accuracy: 0.8340\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 95s 571ms/step - loss: 0.3883 - accuracy: 0.8435\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 86s 516ms/step - loss: 0.3714 - accuracy: 0.8494\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 92s 549ms/step - loss: 0.3537 - accuracy: 0.8591\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 91s 544ms/step - loss: 0.3372 - accuracy: 0.8645\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 87s 520ms/step - loss: 0.3222 - accuracy: 0.8705\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 87s 519ms/step - loss: 0.3108 - accuracy: 0.8765\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 81s 484ms/step - loss: 0.3015 - accuracy: 0.8817\n",
      "334/334 [==============================] - 8s 24ms/step - loss: 1.2804 - accuracy: 0.6230\n"
     ]
    }
   ],
   "source": [
    "#GRU with added features\n",
    "def my_GRU_model_concat(vocabulary_size,embedding_size,input_length,added_shape=3):\n",
    "    tf.keras.backend.clear_session()\n",
    "    embed_input = keras.Input(\n",
    "    shape=(None,)) \n",
    "    inp_num_data_input = keras.Input(\n",
    "        shape=(added_shape,))\n",
    "    \n",
    "    embed_features = keras.layers.Embedding(vocabulary_size, embedding_size)(embed_input)\n",
    "    gru_features = keras.layers.GRU(50)(embed_features)\n",
    "    \n",
    "    # Merge all available features into a single large vector via concatenation\n",
    "    x = keras.layers.concatenate([gru_features, inp_num_data_input])\n",
    "    \n",
    "    #x_norm=tf.keras.layers.BatchNormalization()(x)\n",
    "    class_pred = keras.layers.Dense(3, activation='softmax')(x)\n",
    "    model = keras.Model(\n",
    "        inputs=[embed_input,inp_num_data_input],\n",
    "        outputs=class_pred\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def GRU_concat_train_test(X_train,X_val,y_train,y_val,vocabulary_size, embedding_size,input_length):\n",
    "    model = my_GRU_model_concat(vocabulary_size, embedding_size,input_length) \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer='adam', \n",
    "                 metrics=['accuracy'])\n",
    "    history_gru=model.fit(X_train,y_train,batch_size=256,epochs=20)  #,validation_data=(x_val, y_val)\n",
    "    test_result_gru=model.evaluate(X_val,y_val)\n",
    "    train_loss_gru,train_accu_gru=history_gru.history['loss'],history_gru.history['accuracy']\n",
    "    result=pd.DataFrame({'Model':'GRU_concat','train_accu':[np.mean(train_accu_gru)],'test_accu':[test_result_gru[-1]]})\n",
    "    return result\n",
    "\n",
    "\n",
    "def GRU_concat_get_all_fold_result(data_X,data_y,vocabulary_size, embedding_size,input_length):\n",
    "    all_folds_result=pd.DataFrame([])\n",
    "    for train_index, val_index in kf.split(data_X[0]):\n",
    "        X_train_fold, X_test_fold = data_X[0][train_index], data_X[0][val_index]\n",
    "        y_train_fold, y_test_fold = data_y[train_index], data_y[val_index]\n",
    "        X_train_fold_added, X_test_fold_added = data_X[1][train_index], data_X[1][val_index]        \n",
    "        nfold_result = GRU_concat_train_test([X_train_fold,X_train_fold_added], [X_test_fold,X_test_fold_added], y_train_fold, y_test_fold,vocabulary_size, embedding_size,input_length)\n",
    "        all_folds_result=all_folds_result.append(nfold_result)\n",
    "    mean_result=pd.DataFrame(all_folds_result.mean()).T\n",
    "    mean_result.rename({'train_accu':'mean_train_accu','test_accu':'mean_test_accu'},axis=1,inplace=True)\n",
    "    mean_result['model']=\"GRU_concat\"\n",
    "    return mean_result\n",
    "\n",
    "GRU_added_meanfold_result=GRU_concat_get_all_fold_result([X_train_seq,np.nan_to_num(X_train_added,1)],y_train_seq,vocabulary_size, embedding_size,input_length=max_len)\n",
    "#GRU_added_meanfold_result.to_csv('GRU_added_meanfold_result.csv',index=False)\n",
    "GRU_added_meanfold_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accu</th>\n",
       "      <th>mean_test_accu</th>\n",
       "      <th>model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>add_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568457</td>\n",
       "      <td>0.410566</td>\n",
       "      <td>NB</td>\n",
       "      <td>BOW</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562303</td>\n",
       "      <td>0.413938</td>\n",
       "      <td>NB</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.765379</td>\n",
       "      <td>0.626002</td>\n",
       "      <td>GRU_concat</td>\n",
       "      <td>Trained embedding</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.807474</td>\n",
       "      <td>0.621562</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Trained embedding</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accu  mean_test_accu       model          Embedding  \\\n",
       "0         0.568457        0.410566          NB                BOW   \n",
       "0         0.562303        0.413938          NB              TFIDF   \n",
       "0         0.765379        0.626002  GRU_concat  Trained embedding   \n",
       "0         0.807474        0.621562         GRU  Trained embedding   \n",
       "\n",
       "   add_features  \n",
       "0         False  \n",
       "0         False  \n",
       "0          True  \n",
       "0         False  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_result_df=pd.concat([NB_bow_meanfold_result,NB_tfidf_meanfold_result,GRU_added_meanfold_result,GRU_meanfold_result])\n",
    "mean_result_df['Embedding']=['BOW','TFIDF','Trained embedding','Trained embedding']\n",
    "mean_result_df['add_features']=[False,False,True,False]\n",
    "mean_result_df.rename({'mean_test_accu':'mean_val_accuracy','mean_train_accu':'mean_train_accuracy'},axis=1)\n",
    "mean_result_df.to_csv(\"mean_result_df.csv\",index=False)\n",
    "mean_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Result: As we can see from the result, GRU model using reviews with other user background data (hotel location, revitaewer nationality and days stayes) gives us the best performance using 5 fold cross validation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
